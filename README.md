üìä An√°lise de Performance de LLMs na NVIDIA Jetson

<p align="center">
<img src="results/plots/benchmark_chart.png" alt="Gr√°fico de Benchmark de LLMs na Jetson" width="90%">
</p>

üìú Sobre o Projeto

Este reposit√≥rio cont√©m uma su√≠te de benchmark automatizada para analisar a performance de Modelos de Linguagem de Grande Escala (LLMs) na plataforma embarcada NVIDIA Jetson. O objetivo √© fornecer dados quantitativos sobre como diferentes modelos se comportam sob restri√ß√µes de hardware, especialmente ao variar os modos de consumo de energia e o uso de mem√≥ria swap.

O projeto utiliza um script Python para automatizar a execu√ß√£o, a coleta de m√©tricas e o armazenamento dos resultados, garantindo a reprodutibilidade dos testes.

üéØ Objetivos

    Automatizar o Benchmark: Executar testes de forma sistem√°tica para diferentes LLMs e configura√ß√µes de sistema.

    Analisar Modelos: Avaliar a performance de infer√™ncia (tokens/segundo) de modelos como Llama3, Gemma, DeepSeek e TinyLlama.

    Medir o Impacto do Hardware: Quantificar a influ√™ncia dos modos de energia da Jetson e da ativa√ß√£o da mem√≥ria swap.

    Coletar Dados Estruturados: Salvar todas as m√©tricas de performance em um formato .csv para f√°cil an√°lise e visualiza√ß√£o.

üõ†Ô∏è Stack de Tecnologias

    Hardware: NVIDIA Jetson (Orin, Xavier, etc.)

    Software: Python 3, Ollama

    Bibliotecas Python: PyYAML (para configura√ß√£o), Pandas/Matplotlib (para an√°lise e visualiza√ß√£o de dados).

üöÄ Como Executar o Benchmark

Para replicar esta an√°lise, siga os passos abaixo.

Pr√©-requisitos

    Um dispositivo NVIDIA Jetson com JetPack instalado.

    Ollama instalado e funcionando no dispositivo. (Guia de instala√ß√£o: https://ollama.com/)

Passos

    Clone o reposit√≥rio:
    Bash

git clone https://github.com/Lukasilvestre/jetson-llm-performance-analysis.git
cd jetson-llm-performance-analysis

Instale as depend√™ncias Python:
Bash

pip install -r requirements.txt

Configure seus testes (opcional):
Edite o arquivo config.yaml para mudar os modelos a serem testados, o prompt, ou os modos de energia.

Execute o script de benchmark:
Bash

    python run_benchmark.py

    Siga as instru√ß√µes no terminal: O script ir√° pausar e solicitar que voc√™ configure manualmente o modo de energia e o estado do swap antes de cada bateria de testes. Isso √© crucial para garantir a precis√£o dos resultados.

üìä Resultados

Esta se√ß√£o ser√° preenchida com as conclus√µes ap√≥s a an√°lise do arquivo benchmark_results.csv gerado pelo script.

Exemplo de Tabela de An√°lise:
Modelo	Modo de Energia	Swap Ativado	Tokens/Segundo (eval_rate_tps)
gemma:2b	10W	N√£o	25.4
gemma:2b	MAXN	N√£o	38.1
llama3:8b	MAXN	Sim	11.2
llama3:8b	MAXN	N√£o	(Falhou ou muito lento)

Principais Conclus√µes Preliminares:

    Conclus√£o 1 sobre o impacto do modo de energia...

    Conclus√£o 2 sobre a necessidade de swap para modelos maiores...

    Conclus√£o 3 sobre qual modelo teve o melhor custo-benef√≠cio de performance...

üìÑ Licen√ßa

Este projeto est√° distribu√≠do sob a licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.
